# Routing Cycle Detector

A Python tool that finds the longest routing cycle in claim routing data files. It supports downloading data directly from URLs (including Google Drive) and generates detailed results with logging.

## Description

This script processes claim routing data to find the longest cycle in routing paths. Each line in the input data represents a routing edge with the format:

```
source|destination|claim_id|status_code
```

The algorithm groups edges by `(claim_id, status_code)` pairs and finds the longest simple cycle within each group using depth-first search (DFS).

## Requirements

### Python Version

- **Python 3.8+** (tested with Python 3.10, 3.11, 3.12)

### Dependencies

This project uses **only Python standard library modules** - no external dependencies required:

- `argparse` - Command-line argument parsing
- `urllib.request` - HTTP downloads
- `logging` - Logging functionality
- `collections` - defaultdict for graph building
- `datetime` - Timestamp generation
- `re` - Regular expressions for URL parsing
- `os`, `sys` - System operations

## Installation

1. Clone or download this repository:
   ```bash
   git clone <repository-url>
   cd teste_aithoghtful
   ```

2. No additional installation needed - the script uses only standard library modules.

## Usage

### Basic Usage

```bash
python3 my_solution.py <data_url>
```

### Command Line Arguments

| Argument | Required | Default | Description |
|----------|----------|---------|-------------|
| `data_url` | Yes | - | URL to download the input data file (supports Google Drive links) |
| `--dest-folder` | No | `data` | Destination folder for downloaded file |
| `--results-folder` | No | `results` | Base folder for results |
| `--skip-download` | No | False | Skip download and use existing file in data folder |

### Examples

#### Download and process data from Google Drive:
```bash
python3 my_solution.py "https://drive.google.com/file/d/10WF0EwKH7pac1Pxp3BmRwC_1B1Lxuix0/view?usp=sharing"
```

#### Use existing downloaded file (skip download):
```bash
python3 my_solution.py --skip-download "https://drive.google.com/file/d/10WF0EwKH7pac1Pxp3BmRwC_1B1Lxuix0/view?usp=sharing"
```

#### Custom destination and results folders:
```bash
python3 my_solution.py --dest-folder ./my_data --results-folder ./my_results "https://example.com/data.txt"
```

## Output

### Console Output

The script outputs progress information and the final result:
```
190017,190116,10
```

Format: `claim_id,status_code,cycle_length`

### Results Folder Structure

Each run creates a timestamped subfolder in the results directory:

```
results/
└── run_20260115_203653/
    ├── solution.txt           # The solution result
    ├── solution_metadata.yml  # Run metadata in YAML format
    └── run.log               # Detailed execution log
```

#### solution.txt
Contains the result in CSV format:
```
190017,190116,10
```

#### solution_metadata.yml
Contains run metadata:
```yaml
# Solution Metadata
# Generated by Routing Cycle Detector

run_date: "2026-01-15"
run_time: "20:35:27"
run_timestamp: "2026-01-15T20:35:27.617379"

data_source:
  url: "https://drive.google.com/file/d/..."
  filename: "large_input_v1.txt"

result:
  claim_id: "190017"
  status_code: "190116"
  cycle_length: 10
```

#### run.log
Detailed log with DEBUG level information including:
- Download progress
- File processing progress
- Cycle detection progress
- Any errors or warnings

## Input Data Format

The input file should contain pipe-separated values with 4 fields per line:

```
source|destination|claim_id|status_code
```

Example:
```
A|B|12345|100
B|C|12345|100
C|A|12345|100
```

This represents a cycle: A → B → C → A for claim_id=12345, status_code=100

## Algorithm

1. **Parse Input**: Stream the file line-by-line, grouping edges by `(claim_id, status_code)` into separate directed graphs.

2. **Cycle Detection**: For each graph, use DFS from every node to find simple cycles back to the start node, tracking the longest.

3. **Complexity**:
   - File read: O(n)
   - Cycle detection per graph: O(V!) worst case, but graphs are small in practice

## Google Drive Support

The script automatically handles Google Drive URLs by:
1. Extracting the file ID from various URL formats
2. Converting to a direct download URL
3. Handling the virus scan confirmation for large files

Supported URL formats:
- `https://drive.google.com/file/d/<FILE_ID>/view?usp=sharing`
- `https://drive.google.com/open?id=<FILE_ID>`
- `https://drive.google.com/uc?id=<FILE_ID>`

## Troubleshooting

### Download Issues

If you encounter download problems:
1. Check your internet connection
2. Verify the URL is accessible and the file is shared publicly
3. Check the `run.log` file for detailed error messages

### Memory Issues

For very large files, the script streams the input file line-by-line to minimize memory usage. However, the graph structures are kept in memory. If you run out of memory:
1. Consider processing a subset of the data
2. Use a machine with more RAM

### No Cycles Found

If no cycles are found:
1. Verify the input file format is correct (pipe-separated, 4 fields)
2. Check that the data actually contains cycles
3. Review the `run.log` for processing statistics

## License

MIT License

## Author

Generated for AIThoughtful coding challenge.
